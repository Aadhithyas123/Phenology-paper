seed: 42
device: "cuda"
num_workers: 8
log_dir: "outputs"

dataset:
  name: "EuroCropsML"
  year: 2021
  root_npz: "/mnt/data/preprocess/preprocess"
  pretrain_json: "/mnt/data/split/split/latvia_vs_estonia/pretrain/region_split.json"
  finetune_json_tpl: "/mnt/data/split/split/latvia_vs_estonia/finetune/split_k_strict/region_split_{k}.json"
  master_json: "/mnt/data/split/split/latvia_vs_estonia/finetune/region_split_all.json"

  split: "latvia_vs_estonia"

  countries:
    train: ["LV"]
    extra_train: []
    test: ["EE"]

  # NEW → ensure we only keep labels present in BOTH domains
  only_overlap_with: ["LV", "EE"]

  normalize: "zscore"




paths:
  # Where prep_data.py writes parquet outputs
  processed_dir: "/mnt/data/preprocess/preprocess"
  hypergraph_dir: "hypergraphs"
  outputs_dir: "outputs/lvpt_to_ee_fused"

# ---------- PREP-ONLY KNOBS ----------
prep:
  compute_indices: true         # if true, add NDRE/EVI2/NDWI/MSI events/pulses/lead–lags
  smooth_window: 9              # moving-average window (odd)
  drop_b10: false               # prep loads raw as-is; drop at model time (see loader_defaults)

# ---------- LOADER DEFAULTS (used by training code, harmless for prep) ----------
loader_defaults:
  normalize: "zscore"
  drop_b10: true                # recommended → 12 S2 bands: B01..B12 without B10
  pretraining_mode: true

  pretraining:
  downsample_meadow_to_median: true
  meadow_label_id: 42   # put your true numeric ID here if you use JSON labels



# ---------- FEATURE NOTES (for model code; prep still writes raw summaries + events) ----------
features:
  use_bands:  # 12 S2 bands excluding B10 (cirrus) — matches EuroCropsML
    ["B01","B02","B03","B04","B05","B06","B07","B08","B8A","B09","B11","B12"]
  indices: ["NDVI","EVI2","NDRE","NDWI","MSI"]  # your method may read these from events.parquet
  smoothing:
    method: "mov_avg"
    window: 9
  zscore_per_parcel: true

# ---------- SYNCHRONY / GRAPH (for your co-evolution pipeline; baseline can ignore) ----------
synchrony:
  dt_days: { SOS: 14, Peak: 14, EOS: 21 }
  phase_threshold: 0.7
  neighborhood:
    mode: "nuts"
    nuts_level: 3
    radius_km: 15
    k: 30
  hyperedge_sizes: [3,4,5]

this:
  poly_order: 3
  lags: [0, 1]
  derivative:
    method: "finite_diff"
    dt_days: 5
  sparsity:
    solver: "stlsq"
    lambda: 0.01
    max_iter: 20
    coef_threshold: 1.0e-3
  bootstrap:
    n: 20
    keep_fraction: 0.6
  prune_order_leak: true

graphs:
  fusion: "union"        # "union" | "attention"
  pairwise_graph:
    metric: "dtw"
    k: 15

model:
  head: "protonet"
  hidden_dim: 256
  layers: 2
  dropout: 0.1
  use_hypergraph: true
  hypergraph_source: "sync"   # "fused" | "sync" | "dyn"
  hypergraph_layers: 1

experiment:
  episodes_per_epoch: 100
  ways: 3
  shots: 5
  queries: 15
  epochs: 100
  patience: 10
  optim:
    name: "adamw"
    lr: 3.0e-4
    weight_decay: 1.0e-4
  scheduler:
    name: "cosine"
    warmup_epochs: 3
  loss:
    type: "cross_entropy"
    class_balance: "logit_adjust"
    logit_adjust_tau: 1.0
  temperature_scaling: true

eval:
  seeds: [0,1,2,3,4]
  k_grid: [1,5,20,100,200,500]
  metrics: ["macro_f1","kappa","acc","ece","nll"]
  buckets: ["head","mid","tail"]
  episodes_per_epoch_eval: 50

cross_domain:
  coral:
    enabled: true
    batches: 50

openset:
  enabled: false
  alphas: [0.0, 0.25, 0.5]
  score: "maxprob"
  threshing: "val_opt"
